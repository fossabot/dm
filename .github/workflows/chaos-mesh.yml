name: chaos

# Controls when the action will run. Triggers the workflow on pull request
# events but only for the master and release-2.0 branch
on:
  pull_request:
    branches:
    - master
    - release-2.0

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "base"
  base:
    # The type of runner that the job will run on
    runs-on: ubuntu-18.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Set up Go for building DM, now it's v1.13
    - name: Set up Go 1.13
      uses: actions/setup-go@v2
      with:
        go-version: 1.13
    - name: Print Go version
      run: go version
  
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - name: Check out code
      uses: actions/checkout@v2
    
    # Set up Kubernetes IN Docker
    - name: Set up kind cluster 
      uses: helm/kind-action@v1.0.0
      with:
        cluster_name: dm-chaos 
    - name: Print cluster information
      run: |
        kubectl config view
        kubectl cluster-info
        kubectl get nodes
        kubectl get pods -n kube-system
        kubectl get sc
        helm version
        kubectl version
    
    # Disable AppArmor for MySQL, see https://github.com/moby/moby/issues/7512#issuecomment-61787845
    - name: Disable AppArmor for MySQL
      run: |
        sudo ln -s /etc/apparmor.d/usr.sbin.mysqld /etc/apparmor.d/disable/
        sudo apparmor_parser -R /etc/apparmor.d/usr.sbin.mysqld

    # Build DM binary
    - name: Build DM binary
      run: make dm-master dm-worker dmctl chaos-case
    
    # Build DM docker image
    - name: Build DM docker image
      run: |
        docker build -f $GITHUB_WORKSPACE/chaos/manifests/Dockerfile -t dm:chaos $GITHUB_WORKSPACE/bin
        docker image list
    # Load DM docker image into KIND, see https://kind.sigs.k8s.io/docs/user/quick-start/#loading-an-image-into-your-cluster
    - name: Load DM docker image into KIND
      run: |
        kind load docker-image dm:chaos --name dm-chaos

    # Set up upstream MySQL instances
    - name: Set up MySQL
      run: |
         kubectl apply -f $GITHUB_WORKSPACE/chaos/manifests/mysql.yaml
         kubectl get -f $GITHUB_WORKSPACE/chaos/manifests/mysql.yaml
         kubectl describe -f $GITHUB_WORKSPACE/chaos/manifests/mysql.yaml
    - name: Wait for MySQL ready # kubectl wait --all not working
      run: |
         kubectl wait --for=condition=Ready pod/mysql-0 --timeout=120s || true
         sleep 10
         kubectl wait --for=condition=Ready pod/mysql-1 --timeout=120s || true
         echo show pvc
         kubectl get pvc -l app=mysql -o wide
         echo show pv
         kubectl get pv -o wide
         echo show svc
         kubectl get svc -l app=mysql -o wide
         echo show sts
         kubectl get sts -l app=mysql -o wide
         echo show po
         kubectl get po -l app=mysql -o wide
         echo describe po
         kubectl describe po -l app=mysql
         echo describe pvc
         kubectl describe pvc -l app=mysql
         kubectl wait --for=condition=Ready pod/mysql-0 --timeout=0s
         kubectl wait --for=condition=Ready pod/mysql-1 --timeout=0s

    # Set up downstream TiDB instance (deploy a TiDB with mockTiKV, not a TidbCluster managed by TiDB-operator)
    - name: Set up TiDB
      run: |
        kubectl apply -f $GITHUB_WORKSPACE/chaos/manifests/tidb.yaml
        kubectl get -f $GITHUB_WORKSPACE/chaos/manifests/tidb.yaml
        kubectl describe -f $GITHUB_WORKSPACE/chaos/manifests/tidb.yaml
    - name: Wait for TiDB ready
      run: |
        kubectl wait --for=condition=Ready pod/tidb-0 --timeout=120s || true
        echo show pvc
        kubectl get pvc -l app=tidb -o wide
        echo show pv
        kubectl get pv -o wide
        echo show svc
        kubectl get svc -l app=tidb -o wide
        echo show sts
        kubectl get sts -l app=tidb -o wide
        echo show po
        kubectl get po -l app=tidb -o wide
        echo describe po
        kubectl describe po -l app=tidb
        echo describe pvc
        kubectl describe pvc -l app=tidb
        kubectl wait --for=condition=Ready pod/tidb-0 --timeout=0s

    # Set up DM-master
    - name: Set up DM-master
      run: |
        kubectl apply -f $GITHUB_WORKSPACE/chaos/manifests/dm-master.yaml
        kubectl get -f $GITHUB_WORKSPACE/chaos/manifests/dm-master.yaml
        kubectl describe -f $GITHUB_WORKSPACE/chaos/manifests/dm-master.yaml
    - name: Wait for DM-master ready
      run: |
        kubectl wait --for=condition=Ready pod -l app=dm-master --all || true
        echo "\n" show pvc
        kubectl get pvc -l app=dm-master -o wide
        echo "\n" show pv
        kubectl get pv -o wide
        echo "\n" show svc
        kubectl get svc -l app=dm-master -o wide
        echo "\n" show sts
        kubectl get sts -l app=dm-master -o wide
        echo "\n" show po
        kubectl get po -l app=dm-master -o wide
        echo "\n" describe po
        kubectl describe po -l app=dm-master
        echo "\n" describe pvc
        kubectl describe pvc -l app=dm-master
        echo "\n" show current log for dm-master-0
        kubectl logs dm-master-0 || true
        echo "\n" show previous log for dm-master-0
        kubectl logs dm-master-0 -p || true
        echo "\n" show current log for dm-master-1
        kubectl logs dm-master-1 || true
        echo "\n" show previous log for dm-master-1
        kubectl logs dm-master-1 -p || true
        echo "\n" show current log for dm-master-2
        kubectl logs dm-master-2 || true
        echo "\n" show previous log for dm-master-2
        kubectl logs dm-master-2 -p || true
#        kubectl wait --for=condition=Ready pod -l app=dm-master --all --timeout=0s

    # Set up DM-worker
    - name: Set up DM-worker
      run: |
        kubectl apply -f $GITHUB_WORKSPACE/chaos/manifests/dm-worker.yaml
        kubectl get -f $GITHUB_WORKSPACE/chaos/manifests/dm-worker.yaml
        kubectl describe -f $GITHUB_WORKSPACE/chaos/manifests/dm-worker.yaml
    - name: Wait for DM-worker ready
      run: |
        kubectl wait --for=condition=Ready pod -l app=dm-worker --all || true
        echo "\n" show pvc
        kubectl get pvc -l app=dm-worker -o wide
        echo "\n" show pv
        kubectl get pv -o wide
        echo "\n" show svc
        kubectl get svc -l app=dm-worker -o wide
        echo "\n" show sts
        kubectl get sts -l app=dm-worker -o wide
        echo "\n" show po
        kubectl get po -l app=dm-worker -o wide
        echo "\n" describe po
        kubectl describe po -l app=dm-worker
        echo "\n" describe pvc
        kubectl describe pvc -l app=dm-worker
        echo "\n" show current log for dm-worker-0
        kubectl logs dm-worker-0 || true
        echo "\n" show previous log for dm-worker-0
        kubectl logs dm-worker-0 -p || true
        echo "\n" show current log for dm-worker-1
        kubectl logs dm-worker-1 || true
        echo "\n" show previous log for worker-master-1
        kubectl logs dm-worker-1 -p || true
        echo "\n" show current log for dm-worker-2
        kubectl logs dm-worker-2 || true
        echo "\n" show previous log for dm-worker-2
        kubectl logs dm-worker-2 -p || true
  #        kubectl wait --for=condition=Ready pod -l app=dm-worker --all --timeout=0s

    # Encode chaos-mesh action
    - name: Encode chaos-mesh action
      run: |
        echo "::set-env name=CFG_BASE64::$(base64 -w 0 $GITHUB_WORKSPACE/chaos/manifests/pod-failure-dm.yaml)"

    # Set up chaos-mesh-action
    - name: Run chaos mesh action
      uses: chaos-mesh/chaos-mesh-action@master
      env:
        CFG_BASE64: $(CFG_BASE64)

    # Debug via SSH if previous steps failed
    - name: Set up tmate session
      if: ${{ failure() }}
      uses: mxschmitt/action-tmate@v2
